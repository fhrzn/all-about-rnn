{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "PATH = '../data/names.txt'\n",
    "\n",
    "with open(PATH, 'r', encoding='utf-8') as r:\n",
    "    names = r.read().split('\\n')\n",
    "\n",
    "# shuffle dataset\n",
    "index = list(range(len(names)))\n",
    "random.shuffle(index)\n",
    "names = [names[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[41, 28, 55, 51, 50, 55, 12, 53, 2, 28],\n",
       " [41, 50, 55, 55, 28, 38, 38],\n",
       " [13, 55, 53, 52, 38, 37, 52],\n",
       " [14, 51, 37, 52, 51, 53, 28],\n",
       " [21, 37, 55, 55, 50, 31, 2, 28]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build vocab\n",
    "chars = tuple(set(''.join(names)))\n",
    "int2char = dict(enumerate(chars, 1))\n",
    "int2char[0] = '<PAD>'\n",
    "char2int = {v: k for k, v in int2char.items()}\n",
    "\n",
    "# encode words\n",
    "names_enc = [[char2int[ch] for ch in name] for name in names]\n",
    "names_enc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41, 28, 55, 51, 50, 55, 12, 53,  2, 28,  0,  0,  0,  0,  0],\n",
       "       [41, 50, 55, 55, 28, 38, 38,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [13, 55, 53, 52, 38, 37, 52,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [14, 51, 37, 52, 51, 53, 28,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [21, 37, 55, 55, 50, 31,  2, 28,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad features\n",
    "seq_length = max([len(x) for x in names_enc])\n",
    "\n",
    "def pad_features(names, seq_length):\n",
    "    features = np.zeros((len(names), seq_length), dtype=int)    \n",
    "\n",
    "    for i, row in enumerate(names):\n",
    "        # if seq_length < len(row) then row will be trimmed (expected)        \n",
    "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
    "\n",
    "    return features\n",
    "\n",
    "features = pad_features(names_enc, seq_length)\n",
    "\n",
    "assert len(features) == len(names_enc)\n",
    "assert len(features[0]) == seq_length\n",
    "\n",
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Shapes:\n",
      "===============\n",
      "Train set: (5958, 15)\n",
      "Test set: (1986, 15)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "train_size = .75     # we will use 80% of data as train set\n",
    "# val_size = .5       # we will use 50% of test set as validation set\n",
    "\n",
    "split_id = int(len(features) * train_size)\n",
    "train_x, test_x = features[:split_id], features[split_id:]\n",
    "\n",
    "# test_id = int(len(remain_x) * val_size)\n",
    "# val_x, test_x = remain_x[:test_id], remain_x[test_id:]\n",
    "\n",
    "print('Feature Shapes:')\n",
    "print('===============')\n",
    "print('Train set: {}'.format(train_x.shape))\n",
    "# print('Validation set: {}'.format(val_x.shape))\n",
    "print('Test set: {}'.format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate batches\n",
    "batch_size = 128\n",
    "\n",
    "trainset = TensorDataset(torch.from_numpy(train_x))\n",
    "# validset = TensorDataset(torch.from_numpy(val_x))\n",
    "testset = TensorDataset(torch.from_numpy(test_x))\n",
    "\n",
    "trainloader = DataLoader(trainset, shuffle=True, batch_size=batch_size)\n",
    "# validloader = DataLoader(validset, shuffle=True, batch_size=batch_size)\n",
    "testloader = DataLoader(testset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch size:  torch.Size([128, 15])\n",
      "Sample batch input: \n",
      " tensor([[ 3, 28,  2,  ...,  0,  0,  0],\n",
      "        [36,  2,  2,  ...,  0,  0,  0],\n",
      "        [ 3, 28, 12,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [27, 37, 55,  ...,  0,  0,  0],\n",
      "        [36, 12, 37,  ...,  0,  0,  0],\n",
      "        [14, 53, 11,  ...,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "diter = iter(trainloader)\n",
    "x = diter.next()[0]\n",
    "\n",
    "print('Sample batch size: ', x.size())   # batch_size, seq_length\n",
    "print('Sample batch input: \\n', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture\n",
    "class RNNNamePrediction(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_size=32, dropout=0.2):\n",
    "        super(RNNNamePrediction, self).__init__()\n",
    "\n",
    "        # embedding layer is useful to map input into vector representation\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "        # RNN layer preserved by PyTorch library\n",
    "        # this layer handles RNN Cell loops\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Linear layer for output\n",
    "        self.output = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        # its optional to init hidden state by ourselves\n",
    "        # bcs PyTorch will handle it if we don't provide it\n",
    "\n",
    "        # map input to vector\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # compute current hidden state\n",
    "        o, h = self.rnn(x, h)\n",
    "\n",
    "        # apply dropout\n",
    "        o = self.dropout(o)\n",
    "\n",
    "        # compute output\n",
    "        o = self.output(o)\n",
    "\n",
    "        return o, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# define training device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNNamePrediction(\n",
      "  (embedding): Embedding(56, 16)\n",
      "  (rnn): RNN(16, 128, batch_first=True)\n",
      "  (output): Linear(in_features=128, out_features=56, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model hyperparamters\n",
    "vocab_size = len(char2int)\n",
    "emebdding_dim = 16\n",
    "hidden_dim = 128\n",
    "dropout=0.1\n",
    "\n",
    "model = RNNNamePrediction(vocab_size, hidden_dim, emebdding_dim, dropout)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "grad_clip = 5\n",
    "epochs = 1000\n",
    "print_every = 100\n",
    "history = {\n",
    "    'train_loss': [],    \n",
    "    # 'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    # 'val_acc': [],\n",
    "    'epochs': epochs\n",
    "}\n",
    "MODEL_PATH = '../models/namegen_RNN.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|          | 1/1000 [00:00<10:09,  1.64it/s, Val Loss: 3.286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 | Train Loss: 3.7642 | Val Loss: 3.2856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  10%|█         | 100/1000 [00:52<07:48,  1.92it/s, Val Loss: 0.907]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000 | Train Loss: 0.8997 | Val Loss: 0.9073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  20%|██        | 200/1000 [01:45<06:56,  1.92it/s, Val Loss: 0.848]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000 | Train Loss: 0.8342 | Val Loss: 0.8478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  30%|███       | 300/1000 [02:37<06:14,  1.87it/s, Val Loss: 0.822]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000 | Train Loss: 0.7939 | Val Loss: 0.8220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  40%|████      | 400/1000 [03:36<05:16,  1.90it/s, Val Loss: 0.809]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000 | Train Loss: 0.7665 | Val Loss: 0.8089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  50%|█████     | 500/1000 [04:28<04:23,  1.90it/s, Val Loss: 0.804]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000 | Train Loss: 0.7438 | Val Loss: 0.8035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  60%|██████    | 600/1000 [05:21<03:27,  1.93it/s, Val Loss: 0.800]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000 | Train Loss: 0.7247 | Val Loss: 0.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  70%|███████   | 700/1000 [06:14<02:38,  1.90it/s, Val Loss: 0.801]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700/1000 | Train Loss: 0.7087 | Val Loss: 0.8008\n",
      "[WARNING] Loss did not improving (0.7996 --> 0.8008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  80%|████████  | 800/1000 [07:07<01:45,  1.90it/s, Val Loss: 0.800]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/1000 | Train Loss: 0.6960 | Val Loss: 0.8002\n",
      "[WARNING] Loss did not improving (0.7996 --> 0.8002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  90%|█████████ | 900/1000 [07:59<00:52,  1.90it/s, Val Loss: 0.803]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000 | Train Loss: 0.6859 | Val Loss: 0.8033\n",
      "[WARNING] Loss did not improving (0.7996 --> 0.8033)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 1000/1000 [08:51<00:00,  1.88it/s, Val Loss: 0.805]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000 | Train Loss: 0.6751 | Val Loss: 0.8051\n",
      "[WARNING] Loss did not improving (0.7996 --> 0.8051)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "model = model.to(device)\n",
    "\n",
    "# early stop trigger\n",
    "es_trigger = 0\n",
    "val_loss_min = torch.inf\n",
    "\n",
    "epochloop = tqdm(range(epochs), position=0, desc='Training...', leave=True)\n",
    "\n",
    "for e in epochloop:\n",
    "\n",
    "    #################\n",
    "    # training mode #\n",
    "    #################\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for feature in trainloader:\n",
    "        # transform datatype\n",
    "        feature = feature[0]\n",
    "        feature = feature.type(torch.LongTensor)\n",
    "\n",
    "        # move to device\n",
    "        feature = feature.to(device)\n",
    "\n",
    "        # reset optimizer\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        out, _ = model(feature)\n",
    "        pred = out[:, :-1]\n",
    "        actual = feature[:, 1:]\n",
    "\n",
    "        # compute loss\n",
    "        # example:\n",
    "        # input = 'maxim'\n",
    "        # out     = ['m', 'a', 'x', 'i']\n",
    "        # feature = ['a', 'x', 'i', 'm']\n",
    "        loss = criterion(pred.contiguous().view(-1, len(char2int)),\n",
    "                         actual.contiguous().view(-1))\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # clip gradient\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        # update optimizer\n",
    "        optim.step()\n",
    "\n",
    "        # write loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # write history loss\n",
    "    history['train_loss'].append(train_loss/len(trainloader))\n",
    "\n",
    "    \n",
    "    ####################\n",
    "    # validation model #\n",
    "    ####################\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for feature in testloader:\n",
    "            # transform datatype\n",
    "            feature = feature[0].type(torch.LongTensor)            \n",
    "\n",
    "            # move to device\n",
    "            feature = feature.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            out, _ = model(feature)\n",
    "            pred = out[:, :-1]\n",
    "            actual = feature[:, 1:]\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(pred.contiguous().view(-1, len(char2int)),\n",
    "                         actual.contiguous().view(-1))\n",
    "\n",
    "            # write loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # write loss history\n",
    "    history['val_loss'].append(val_loss / len(testloader))\n",
    "\n",
    "    # put back model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # add epoch meta info\n",
    "    epochloop.set_postfix_str(f'Val Loss: {val_loss/len(testloader):.3f}')\n",
    "\n",
    "    # print epoch\n",
    "    if (e+1) % print_every == 0 or e == 0:\n",
    "        epochloop.write(f'Epoch {e+1}/{epochs} | Train Loss: {train_loss/len(trainloader):.4f} | Val Loss: {val_loss/len(testloader):.4f}')        \n",
    "        epochloop.update()\n",
    "\n",
    "        # save model if validation loss decrease\n",
    "        if val_loss/len(testloader) <= val_loss_min:\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            val_loss_min = val_loss / len(testloader)\n",
    "            es_trigger = 0\n",
    "        else:\n",
    "            epochloop.write(f'[WARNING] Loss did not improving ({val_loss_min:.4f} --> {val_loss/len(testloader):.4f})')\n",
    "            es_trigger += 1\n",
    "\n",
    "        # force early stop\n",
    "        if es_trigger >= 5:\n",
    "            epochloop.write(f'Early stopped at Epoch-{e}')\n",
    "            # update epochs history\n",
    "            history['epochs'] = e+1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.figure(figsize=(6, 8))\n",
    "plt.plot(range(history['epochs']), history['train_loss'], label='Train Loss')\n",
    "plt.plot(range(history['epochs']), history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(model, phrase='A', max_length=6, temperature=1.0, top_k=None):\n",
    "    x_enc = [[char2int[ch] for ch in phrase]]\n",
    "    # x_pad = pad_features(x_enc, max_length)\n",
    "    x_torch = torch.tensor(x_enc, dtype=torch.int64)\n",
    "\n",
    "    # create list for output\n",
    "    char_out = phrase.split()\n",
    "\n",
    "    # move to device\n",
    "    x_torch = x_torch.to(device)\n",
    "\n",
    "    # init empty hidden state\n",
    "    h = None\n",
    "\n",
    "    # running through seed phrase to generate hidden_state\n",
    "    # here we leave the last character cz we will feed it in\n",
    "    # the generating phase as the first sequence\n",
    "    for i in range(len(phrase)-1):\n",
    "        out, h = model(x_torch[:, i:i+1], h)\n",
    "\n",
    "    # start generating\n",
    "    for _ in range(max_length - len(phrase)):\n",
    "        out, h = model(x_torch[:, -1:], h)\n",
    "        p = F.softmax(out / temperature, dim=-1).data        \n",
    "\n",
    "        # pick top K token by top_k (if defined)\n",
    "        if top_k is None:\n",
    "            top_char = np.arange(len(char2int))\n",
    "        else:\n",
    "            p, top_char = p.topk(top_k)\n",
    "            top_char = top_char.numpy().squeeze()        \n",
    "\n",
    "        # select next token and push it to input sequence\n",
    "        p = p.numpy().squeeze()\n",
    "        char_id = np.random.choice(top_char, p=p/p.sum())\n",
    "        char = torch.tensor([[char_id]], dtype=torch.int64)\n",
    "        x_torch = torch.cat([x_torch, char], dim=-1)\n",
    "    \n",
    "        # push to char_out too\n",
    "        char_out.append(int2char[char_id] if char_id > 0 else ' ')\n",
    "\n",
    "    return ''.join(char_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euryl           \n"
     ]
    }
   ],
   "source": [
    "gen = generate_sample(model, phrase='Eu', max_length=16)\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alis            \n",
      "Alessine        \n",
      "Attoris         \n",
      "Avis            \n",
      "Ali             \n",
      "Alena           \n",
      "Adwin           \n",
      "Alyse           \n",
      "Anstelin        \n",
      "Abe             \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    gen = generate_sample(model, phrase='A', max_length=16)\n",
    "    print(gen)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
